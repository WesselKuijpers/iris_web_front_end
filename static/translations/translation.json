{
    "en": {
        "translations": {
            "page.index.upload.caption": "Tap to upload photo",
            "page.index.result.try-again.button": "Try Again!",
            "page.index.result.survey.title": "Help us out?",
            "page.index.result.survey.dropdown.default": "Did it work?",
            "page.index.result.survey.dropdown.positive": "yes",
            "page.index.result.survey.dropdown.negative": "no",
            "page.index.result.survey.answered.thank-you": "Thank you!",
            "page.index.result.survey.answered.dropdown.default": "Then what is it?",
            "base.navbar.link.home": "home",
            "base.navbar.link.insight": "insights",
            "base.navbar.link.rate": "rate",
            "insight.jumbotron.title": "Argos IRIS Insights",
            "insight.jumbotron.lead": "This page contains all the information about the inner workings of Argos IRIS, as well as metrics calculated on the model. <br> The data on this page is continuously being updated with the latest metrics, because the model is constantly adapting to new data.",
            "insight.accuracy-and-loss.intro.title": "Accuracy and Loss",
            "insight.accuracy-and-loss.intro.lead": "Below you will find the metrics for the accuracy and loss of the current model during the training process. <br> The lines labled 'training accuracy' and 'training loss' contain the metrict during the actual process with data that the model has 'seen' before. <br> The lines labled 'validation accuracy' and 'validation loss' show how the model preformed in predicting data that was never seen before. <br> Ideally, the validation line should closely follow the training line.",
            "insight.accuracy-and-loss.accuracy.title": "Accuracy",
            "insight.accuracy-and-loss.accuracy.subtitle": "Higher is better, in percentage",
            "insight.accuracy-and-loss.accuracy.explanation": "The accuracy of a model is usually determined after the model parameters are learned and fixed and no learning is taking place. Then the test samples are fed to the model and the number of mistakes (zero-one loss) the model makes are recorded, after comparison to the true targets. Then the percentage of misclassification is calculated. <br> For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is 95.2%.",
            "insight.accuracy-and-loss.loss.title": "Loss",
            "insight.accuracy-and-loss.loss.subtitle": "Lower is better",
            "insight.accuracy-and-loss.loss.explanation": "Loss value implies how well or poorly a certain model behaves after each iteration of optimization. Ideally, one would expect the reduction of loss after each, or several, iteration(s). <br> Loss is often used in the training process to find the 'best' parameter values for your model (e.g. weights in neural network). It is what you try to optimize in the training by updating weights.",
            "insight.classification-report.intro.title": "Classification Report",
            "insight.classification-report.intro.lead": "When a training process is finished a report is generated to validate the precision of the model. <br> This report is generated by running 10402 images the model has never seen before by it. The model then gives it's prediction, the outcome of this, matched with the actual label of the respective images, is fed into several mathematical functions returning the metrics below.",
            "insight.classification-report.support.title": "Support",
            "insight.classification-report.support.subtitle": "How many images exist inside each category of the test set",
            "insight.classification-report.precision.title": "Per class precision",
            "insight.classification-report.precision.subtitle": "in percentages",
            "insight.classification-report.precision.explanation": "Precision – Accuracy of positive predictions. <br> The precision is being calculated with the following formula:",
            "insight.classification-report.precision.formula": "Precision = True Positives / (True Positives + False Positives)",
            "insight.classification-report.recall.title": "Per class recall score",
            "insight.classification-report.recall.subtitle": "in percentages",
            "insight.classification-report.recall.explanation": "Recall (sensitivity or true positive rate) – Fraction of positives That were correctly identified. <br> The Recall Score is being calculated with the following formula:",
            "insight.classification-report.recall.formula": "Precision = True Positives / (True Positives + False Negatives)",
            "insight.classification-report.f1.title": "Per class F1 score",
            "insight.classification-report.f1.subtitle": "in percentages",
            "insight.classification-report.f1.explanation": "F1 Score (F-Score or F-Measure) – A metric for comparing two classifiers. F1 Score takes into account precision and the recall. It is created by finding the the harmonic mean of precision and recall. <br> The F1 Score is being calculated with the following formula:",
            "insight.classification-report.f1.formula": "F1 = 2 x (precision x recall)/(precision + recall)",
            "insight.confusion-matrix.intro.title": "Confusion Matrix",
            "insight.confusion-matrix.intro.lead": "When a training process is finished a confusion matrix is generated to give a better insight in the precision of the model. <br> The confusion matrix shows how often certain classes are predicted and how images are misclassified. Ideally a digagonal 'line' should be discernable in the confusion matrix.",
            "insight.confusion-matrix.table.title": "Confusion Matrix",
            "insight.confusion-matrix.table.subtitle": "A matrix, labeled by class",
            "insight.current-training.title": "Current Training",
            "insight.current-training.lead": "The model that we use to make predictions is constantly improving. The metrics below give insight into the training that is currently being conducted.",
            "insight.current-training.progress.title": "Progress:",
            "insight.current-training.metrics.title": "Metrics:",
            "insight.current-training.metrics.accuracy": "Accuracy",
            "insight.current-training.metrics.validation-accuracy": "Validation Accuracy",
            "insight.current-training.metrics.loss": "Loss",
            "insight.current-training.metrics.validation-loss": "Validation Loss",
            "insight.current-situation.metrics.accuracy.popover": "The accuracy of a model is usually determined after the model parameters are learned and fixed and no learning is taking place. Then the test samples are fed to the model and the number of mistakes (zero-one loss) the model makes are recorded, after comparison to the true targets. Then the percentage of misclassification is calculated. <br> For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is 95.2%. <br> Higher is better.",
            "insight.current-situation.metrics.validation-accuracy.popover": "The validation accuracy metric is calculated in the same way the accuracy is. <br> The difference is that the validation accuracy is calculated on data that the model has never 'seen' before. <br> For a perfect model this should be the same as the accuracy but in practice this rarely happens",
            "insight.current-situation.metrics.loss.popover": "Loss value implies how well or poorly a certain model behaves after each iteration of optimization. Ideally, one would expect the reduction of loss after each, or several, iteration(s). Loss is often used in the training process to find the 'best' parameter values for your model (e.g. weights in neural network). It is what you try to optimize in the training by updating weights.<br> Lower is better.",
            "insight.current-situation.metrics.validation-loss.popover": "The validation loss is calculated the same way the loss is calculated, it is different because the validation is calculated on data that the model has never seen before. In the perfect situation the validation loss should be the same as the loss, but this rarely happens",
            "insight.training-explanation.title": "How does Argos IRIS work",
            "insight.training-explanation.content": "When a prediction is made using Argos IRIS and the survey is subsequently answered, new data is added to our dataset. This data in itself is not improving the model yet. The model (needed to make predictions) needs to update itself with the new knowledge. To do this a so-called training process is started.  <br> This process runs continuously, and asyncronously with our prediction service so that the user experience is not hindered in any way. <br><br> The model that we use is a deeply trained MobileNet model. This model is made out of several layers with their own responsibility. <br> When a prediction is made a single image is passed through these layers and a so-called 'feature map' is created containing indexes of similarity with known patterns. This 'feature map' will be compared with known classes and based on that a prediction will be given. <br><br> During a training process a stream of images is fed into the model, again, the model makes a prediction per image. Now the correct label is also given to the model. <br> The model can now update it's 'weights' so that the patterns that were discerned in the image can be used to recognise images of the same class in the future. This process continues, and so the model 'learns' new patterns. <br> This process repeats for each image in the dataset, and for 100 iterations (or Epochs). After this process is completed the model will be loaded into the prediction service, some metrics will be generated and the training process will restart. "
        },
        "fullname": "English",
        "force_rtl": false
    },
    "nl": {
        "translations": {
            "page.index.upload.caption": "Tik om foto te uploaden",
            "page.index.result.try-again.button": "Opnieuw!",
            "page.index.result.survey.title": "Handje helpen?",
            "page.index.result.survey.dropdown.default": "Klopt de voorspelling?",
            "page.index.result.survey.dropdown.positive": "ja",
            "page.index.result.survey.dropdown.negative": "nee",
            "page.index.result.survey.answered.thank-you": "Bedankt!",
            "page.index.result.survey.answered.dropdown.default": "Wat is het dan?",
            "base.navbar.link.home": "home",
            "base.navbar.link.insight": "statistieken",
            "base.navbar.link.rate": "beoordelen",
            "insight.jumbotron.title": "Argos IRIS statistieken",
            "insight.jumbotron.lead": "Deze pagina bevat informatie over de werking van Argos IRIS, evenals statistieken berekend op basis van het gebruikte model. <br> De data op deze pagina wordt constant geüpdate omdat het model zich constant aanpast aan nieuwe data.",
            "insight.accuracy-and-loss.intro.title": "'Accuracy' en 'Loss'",
            "insight.accuracy-and-loss.intro.lead": "Hieronder staan statisitieken over de 'accuracy' en 'loss' van het huidige model tijdens de laatste trainingsperiode. <br> De lijnen met label 'training accuracy' en 'training loss' bevatten de gevens tijdens het daadwerkelijke proces met data die het model al eerder heeft 'gezien'. <br> De lijnen met labels 'validation accuracy' en 'validation loss' laten zien hoe goed het model presteert tijdens het voorspellen van data die het nog niet eerder heeft 'gezien'. <br> In de ideale situatie volgt de validatielijn de trainingslijn op de voet.",
            "insight.accuracy-and-loss.accuracy.title": "Accuracy",
            "insight.accuracy-and-loss.accuracy.subtitle": "Hoe hoger, hoe beter. Een percentage",
            "insight.accuracy-and-loss.accuracy.explanation": "De accuracy van een model wordt over het algemeen vastgesteld nadat de parameters van het model vastgelegd en geleerd zij en er niet meer geleerd wordt. De test data wordt aan het model gegeven en het aantal fouten (zero-one loss) die het model maakt worden opgeslagen, nadat de vergelijking met de 'echte' labels is gemaakt. Daarna wordt het percentage van misvattingen berekend. <br> Een voorbeeld: als het aantal testafbeeldingen 1000 is en het model classificeerd 952 van deze correct, dan is de 'accuracy' van het model 95.2%.",
            "insight.accuracy-and-loss.loss.title": "Loss",
            "insight.accuracy-and-loss.loss.subtitle": "Hoe lager, hoe beter",
            "insight.accuracy-and-loss.loss.explanation": "De 'loss'- waarde impliceert hoe 'goed' of 'slecht' het model presteert na elke iteratie van optimalisatie. Idealiter is te verwachten dat deze waarde na elke iteratie afneemt. <br> Loss wordt gebruikt om de 'beste' parameters voor modeltraining the vinden (bijvoorbeeld 'weights' in neuraal netwerk). Dit optimalizeren gebeurt door de 'weights' te updaten.",
            "insight.classification-report.intro.title": "Classificatie rapport",
            "insight.classification-report.intro.lead": "Wanneer een trainingsprocess wort afgesloten wordt er automatisch een classificatieraport gegenereerd om de prestatie van het model te kunnen meten. <br> Dit rapport wordt gegenereerd door 10402 afbeeldingen, die het model nog nooit gezien heeft, aan het model te laten zien. Het model geeft zijn voorspelling, de uitkomst hiervan, gepaard met het 'echte' bijbehpordende label, wordt gebruikt in verschillende wiskundige functies. Dit levert de onderstaande statistieken op.",
            "insight.classification-report.support.title": "Support",
            "insight.classification-report.support.subtitle": "Hoeveel afbeeldingen bevat elke categorie van de testdataset.",
            "insight.classification-report.precision.title": "Precisie per klasse",
            "insight.classification-report.precision.subtitle": "Een percentage",
            "insight.classification-report.precision.explanation": "Precisie – nauwkeurigheid van positieve voorspellingen. <br> De precisie wordt berekend aan de hand van de volgende formule:",
            "insight.classification-report.precision.formula": "Precisie = terechte positieven / (terechte positieven + onterechte positieven)",
            "insight.classification-report.recall.title": "'Recall' -score per klasse",
            "insight.classification-report.recall.subtitle": "Een percentage",
            "insight.classification-report.recall.explanation": "Recall (gevoeligheid of mate van terechte positieven) – Fractie van de positieven de juist geïdentificeerd zijn. <br> De 'recall' score wordt met de volgende formule berekend:",
            "insight.classification-report.recall.formula": "Recall = terechte positieven / (terechte positieven + onterechte negatieven)",
            "insight.classification-report.f1.title": "F1-score per klasse",
            "insight.classification-report.f1.subtitle": "Een percentage",
            "insight.classification-report.f1.explanation": "F1 Score – Een methode om twee waarden te vergelijken. F1-Score neemt zowel de precision als de 'recall' in acht. Ze wordt gevormd door de harmonie in de precisie en 'recall' te vinden. <br> De F1-score wordt volgens de volgende formule berekend:",
            "insight.classification-report.f1.formula": "F1 = 2 x (precisie x recall)/(precisie + recall)",
            "insight.confusion-matrix.intro.title": "Confusion Matrix",
            "insight.confusion-matrix.intro.lead": "Wanneer een trainprocess voltooid is wordt er een confusion matrix gegenereed, deze geeft inzicht in de voorspellingen die door het model gemaakt worden. Idealiter zou er een diagonale 'lijn' in de matrix zichtbaar moeten zijn.",
            "insight.confusion-matrix.table.title": "Confusion Matrix",
            "insight.confusion-matrix.table.subtitle": "Een matrix, per klasse",
            "insight.current-training.title": "Huidige Training",
            "insight.current-training.lead": "Het model dat gebruikt wordt om voorspellingen te maken wordt constant aangepast aan nieuwe data. The statistieken hieronder geven inzicht in het huidige trainingsproces.",
            "insight.current-training.progress.title": "Voortgang:",
            "insight.current-training.metrics.title": "Statistieken:",
            "insight.current-training.metrics.accuracy": "Accuracy",
            "insight.current-training.metrics.validation-accuracy": "Validation Accuracy",
            "insight.current-training.metrics.loss": "Loss",
            "insight.current-training.metrics.validation-loss": "Validation Loss",
            "insight.current-situation.metrics.accuracy.popover": "De accuracy van een model wordt over het algemeen vastgesteld nadat de parameters van het model vastgelegd en geleerd zij en er niet meer geleerd wordt. De test data wordt aan het model gegeven en het aantal fouten (zero-one loss) die het model maakt worden opgeslagen, nadat de vergelijking met de 'echte' labels is gemaakt. Daarna wordt het percentage van misvattingen berekend. <br> Een voorbeeld: als het aantal testafbeeldingen 1000 is en het model classificeerd 952 van deze correct, dan is de 'accuracy' van het model 95.2%. <br> Hoe Hoger, hoe beter.",
            "insight.current-situation.metrics.validation-accuracy.popover": "De 'validation accuracy' wordt op eenzelfde manier als de 'accuracy' berkend. <br> Het verschil is dat de 'validation accuracy' berkend wordt op data die het model nog nooit gezien heeft. <br> Als het model perfect is moet deze waarde hetzelfde zijn als de 'accuracy'. Dit gebeurt zelden",
            "insight.current-situation.metrics.loss.popover": "De 'loss'- waarde impliceert hoe 'goed' of 'slecht' het model presteert na elke iteratie van optimalisatie. Idealiter is te verwachten dat deze waarde na elke iteratie afneemt. <br> Loss wordt gebruikt om de 'beste' parameters voor modeltraining the vinden (bijvoorbeeld 'weights' in neuraal netwerk). Dit optimalizeren gebeurt door de 'weights' te updaten.<br> Hoe lager, hoe beter.",
            "insight.current-situation.metrics.validation-loss.popover": "De 'validation loss' wordt op dezelfde manier berekend als de 'loss' -waarde, het verschil is dat deze waarde wordt berekend op data die het model nog niet eerder heeft 'gezien'. In de prefecte situatie is deze waarde gelijk aan de 'loss' -waarde, dit gebeurt zeer zelden",
            "insight.training-explanation.title": "Hoe werkt Argos IRIS",
            "insight.training-explanation.content": "Wanneer er een voorspelling gemaakt wordt met Argos IRIS en de enquete wordt beantwoord wordt er nieuwe data aan onze dataset toegevoegd. Deze nieuwe data op zich verbeterd het model nog niet. Het model (hiermee worden de voorspellingen gemaakt) moet geupdate worden met de nieuwe data. Om deze reden wordt een nieuw train-proces gestart. <br> Dit proces loopt continue, en asynchroon met onze voorspelservice zodat het gebruik van Argos IRIS niet wordt verhinderd. <br><br>Het model waar wij gebruik van maken is een diep getraind MobileNet model. Dit model bestaat uit verschillende lagen, elk met zijn eigen verantwoordelijkheid. <br> Wanneer er een voorspelling wordt gemaakt wordt er aan de hand van bekende patronen een zogenaamde 'feature map' gercreeerd met indexen van overeenkomst met bekende klassen. deze 'feature map' wordt vergeleken met bekende klassen om zo een voorspelling te kunnen doen. <br><br> Gedurende een training-proces wordt er een stroom van afbeeldingen aan het model gegeven, wederom doet het model per afbeelding een voorspelling. In deze situatie wordt het correcte label ook met de afbeelding meegegeven. <br> zo kan het model zijn 'weights' updaten zodat patronen die uit de afbeelding gehaald zijn gebruikt kunnen worden om afbeeldingen van dezelfde klasse te herkennen in de toekomst. Dit proces loopt door en zo leert het model nieuwe patronen. <br> Dit proces loopt door voor elke afbeelding in de dataset, en voor 100 iteraties (of Epochs). Wanneer dit process klaar is wordt het nieuwe model ingeladen, een paar statistieken worden gegenereerd en het train-proces wordt opnieuw gestart. "
        },
        "fullname": "Nederlands",
        "force_rtl": false
    },
    "fr": {
        "translations": {
            "page.index.upload.caption": "Cliquer pour télécharger une photo",
            "page.index.result.try-again.button": "Réessayer",
            "page.index.result.survey.title": "Aidez-nous ?",
            "page.index.result.survey.dropdown.default": "Cela a-t-il fonctionné ?",
            "page.index.result.survey.dropdown.positive": "Oui",
            "page.index.result.survey.dropdown.negative": "Non",
            "page.index.result.survey.answered.thank-you": "Merci!",
            "page.index.result.survey.answered.dropdown.default": "Alors qu'est-ce que c'est?",
            "base.navbar.link.home": "Acceuil",
            "base.navbar.link.insight": "Aperçu",
            "base.navbar.link.rate": "Taux",
            "insight.jumbotron.title": "Aperçu Argos IRIS",
            "insight.jumbotron.lead": "Cette page contient toutes les informations sur le fonctionnement interne d’Argos IRIS, ainsi que les mesures calculées sur le modèle. <br> Les données de cette page sont constamment mises à jour avec les dernières mesures car le modèle s'adapte constamment à de nouvelles données.",
            "insight.accuracy-and-loss.intro.title": "Précision et perte",
            "insight.accuracy-and-loss.intro.lead": "Vous trouverez ci-dessous les paramètres de précision et de perte du modèle actuel au cours du processus de formation. <br> Les lignes intitulées 'précision de la formation' et 'perte de formation' contiennent le paramétre au cours du processus réel avec des données que le modèle a 'vues' auparavant. <br> Les lignes intitulées 'précision de la validation' et 'perte de la validation' montrent comment le modèle a préformé pour la prévision de données jamais vues auparavant. <br> Idéalement, la ligne de validation devrait suivre de près la ligne de formation.",
            "insight.accuracy-and-loss.accuracy.title": "Précision",
            "insight.accuracy-and-loss.accuracy.subtitle": "Plus haut, mieux, en pourcentage",
            "insight.accuracy-and-loss.accuracy.explanation": "La précision d'un modèle est généralement déterminée une fois que les paramètres du modèle ont été appris et fixés et qu'aucun apprentissage n'a lieu. Ensuite, les échantillons de test sont introduits dans le modèle et le nombre d'erreurs (perte zéro-un) du modèle est enregistré, après comparaison avec les véritables objectifs. Ensuite, le pourcentage d'erreur de classification est calculé. <br> Par exemple, si le nombre d'échantillons de test est égal à 1000 et que le modèle en classe 952 correctement, la précision du modèle est de 95,2%.",
            "insight.accuracy-and-loss.loss.title": "Perte",
            "insight.accuracy-and-loss.loss.subtitle": "Plus bas c'est mieux",
            "insight.accuracy-and-loss.loss.explanation": "La valeur de perte indique dans quelle mesure un modèle donné se comporte bien après chaque itération d'optimisation. Idéalement, on s'attendrait à une réduction des pertes après chaque ou plusieurs itérations. La perte est souvent utilisée dans le processus de formation pour trouver les «meilleures» valeurs de paramètres de votre modèle (par exemple, les poids dans le réseau de neurones). C’est ce que vous essayez d’optimiser dans l’entraînement en mettant à jour les poids.",
            "insight.classification-report.intro.title": "Rapport de classification",
            "insight.classification-report.intro.lead": "Lorsqu'un processus de formation est terminé, un rapport est généré pour valider la précision du modèle. <br> Ce rapport est généré en exécutant 10402 images que le modèle n'a jamais vues auparavant. Le modèle donne ensuite sa prévision, dont le résultat, associé à l'étiquette réelle des images respectives, est introduit dans plusieurs fonctions mathématiques renvoyant les métriques ci-dessous.",
            "insight.classification-report.support.title": "Support",
            "insight.classification-report.support.subtitle": "Combien d'images existe dans chaque catégorie de l'ensemble de test",
            "insight.classification-report.precision.title": "Précision par classe",
            "insight.classification-report.precision.subtitle": "En pourcentages",
            "insight.classification-report.precision.explanation": "Précision - Exactitude des prédictions positives. <br> La précision est calculée avec la formule suivante:",
            "insight.classification-report.precision.formula": "Précision = Vrais Positifs / (Vrais Positifs + Faux Positifs)",
            "insight.classification-report.recall.title": "Score de rappel par classe",
            "insight.classification-report.recall.subtitle": "En pourcentages",
            "insight.classification-report.recall.explanation": "Rappel (sensibilité ou véritable taux positif) - Fraction de positifs correctement identifiés. <br> Le score de rappel est calculé avec la formule suivante:",
            "insight.classification-report.recall.formula": "Précision = vrais positifs / (vrais positifs + faux négatifs)",
            "insight.classification-report.f1.title": "Score F1 par classe",
            "insight.classification-report.f1.subtitle": "En pourcentages",
            "insight.classification-report.f1.explanation": "F1 Score (F-Score ou F-Mesure) - Une métrique pour comparer deux classificateurs. Le score F1 prend en compte la précision et le rappel. Il est créé en trouvant la moyenne harmonique de précision et de rappel. <br> Le score F1 est calculé avec la formule suivante:",
            "insight.classification-report.f1.formula": "F1 = 2 x (rappel x précision) / (précision + rappel)",
            "insight.confusion-matrix.intro.title": "Matrice de confusion",
            "insight.confusion-matrix.intro.lead": "Lorsqu'un processus de formation est terminé, une matrice de confusion est générée pour donner un meilleur aperçu de la précision du modèle. <br> La matrice de confusion indique la fréquence à laquelle certaines classes sont prédites et la classification erronée des images. Idéalement, une «ligne» digagonale devrait être discernable dans la matrice de confusion.",
            "insight.confusion-matrix.table.title": "Matrice de confusion",
            "insight.confusion-matrix.table.subtitle": "Une matrice, étiquetée par classe",
            "insight.current-training.title": "Formation en cours",
            "insight.current-training.lead": "Le modèle que nous utilisons pour faire des prévisions s’améliore constamment. Les métriques ci-dessous donnent un aperçu de la formation en cours.",
            "insight.current-training.progress.title": "Progrès",
            "insight.current-training.metrics.title": "Métrique",
            "insight.current-training.metrics.accuracy": "Précision",
            "insight.current-training.metrics.validation-accuracy": "Précision de validation",
            "insight.current-training.metrics.loss": "Perte",
            "insight.current-training.metrics.validation-loss": "Perte de validation",
            "insight.current-situation.metrics.accuracy.popover": "La précision d'un modèle est généralement déterminée une fois que les paramètres du modèle ont été appris et fixés et qu'aucun apprentissage n'a lieu. Ensuite, les échantillons de test sont introduits dans le modèle et le nombre d'erreurs (zéro perte) du modèle est enregistré, après comparaison avec les véritables objectifs. Ensuite, le pourcentage d'erreur de classification est calculé. <br> Par exemple, si le nombre d'échantillons de test est égal à 1000 et que le modèle en classe 952 correctement, la précision du modèle est de 95,2%. <br> Plus c'est mieux.",
            "insight.current-situation.metrics.validation-accuracy.popover": "La métrique d’exactitude de la validation est calculée de la même manière que l’exactitude. <br> La différence est que la précision de la validation est calculée sur des données que le modèle n'a jamais vues auparavant. <br> Pour un modèle parfait, cela devrait être identique à la précision, mais cela se produit rarement en pratique.",
            "insight.current-situation.metrics.loss.popover": "La valeur de perte indique dans quelle mesure un modèle donné se comporte bien après chaque itération d'optimisation. Idéalement, on s'attendrait à une réduction des pertes après chaque ou plusieurs itérations. La perte est souvent utilisée dans le processus de formation pour trouver les «meilleures» valeurs de paramètres de votre modèle (par exemple, les poids dans le réseau de neurones). C’est ce que vous essayez d’optimiser dans l’entraînement en mettant à jour les poids. <br> Plus bas est meilleur.",
            "insight.current-situation.metrics.validation-loss.popover": "La perte de validation est calculée de la même manière que la perte, mais elle est différente car la validation est calculée sur des données que le modèle n'a jamais vues auparavant. Dans la situation idéale, la perte de validation doit être identique à la perte, mais cela se produit rarement.",
            "insight.training-explanation.title": "Comment fonctionne Argos IRIS",
            "insight.training-explanation.content": "Lorsqu'une prévision est faite à l'aide d'Argos IRIS et que l'on répond ensuite à l'enquête, de nouvelles données sont ajoutées à notre ensemble de données. Ces données en elles-mêmes n'améliorent pas encore le modèle. Le modèle (nécessaire pour faire des prévisions) doit se mettre à jour avec les nouvelles connaissances. Pour ce faire, un processus de formation est démarré. <br> Ce processus fonctionne en permanence et de manière asynchrone avec notre service de prévision, de sorte que l'expérience utilisateur ne soit aucunement entravée. <br> <br> Le modèle que nous utilisons est un modèle MobileNet profondément formé. Ce modèle est composé de plusieurs couches avec leur propre responsabilité. <br> Quand une prédiction est faite, une seule image est passée à travers ces couches et une 'carte de caractéristiques' est créée, contenant des index de similarité avec des modèles connus. Cette 'carte de caractéristiques' sera comparée aux classes connues et sera basée sur une prédiction. <br> <br> Au cours d'un processus de formation, un flux d'images est introduit dans le modèle. De nouveau, le modèle effectue une prédiction par image. Maintenant, l'étiquette correcte est également donnée au modèle. <br> Le modèle peut maintenant mettre à jour ses 'poids' de sorte que les modèles qui ont été discernés dans l'image puissent être utilisés pour reconnaître des images de la même classe à l'avenir. Ce processus se poursuit et le modèle «apprend» ainsi de nouveaux modèles. <br> Ce processus se répète pour chaque image du jeu de données et pour 100 itérations (ou Epochs). Une fois ce processus terminé, le modèle sera chargé dans le service de prévision, des mesures seront générées et le processus de formation redémarrera."
        },
        "fullname": "Français",
        "force_rtl": false
    },
    "ar": {
        "translations": {
            "page.index.upload.caption": "انقر لتحميل الصورة",
            "page.index.result.try-again.button": "مرة أخرى",
            "page.index.result.survey.title": "ساعدني",
            "page.index.result.survey.dropdown.default": "هل التنبؤ صحيح؟",
            "page.index.result.survey.dropdown.positive": "نعم",
            "page.index.result.survey.dropdown.negative": "لا",
            "page.index.result.survey.answered.thank-you": "شكر",
            "page.index.result.survey.answered.dropdown.default": "ما هو إذن؟",
            "base.navbar.link.home": "الصفحة الرئيسية",
            "base.navbar.link.insight": "إحصائيات",
            "base.navbar.link.rate": "القاضي",
            "insight.jumbotron.title": " Argos IRIS إحصائيات",
            "insight.jumbotron.lead": "تحتوي هذه الصفحة على معلومات حول تشغيل Argos IRIS ، وكذلك الإحصاءات المحسوبة على أساس النموذج المستخدم <br> يتم تحديث البيانات في هذه الصفحة باستمرار لأن النموذج يتكيف باستمرار مع البيانات الجديدة",
            "insight.accuracy-and-loss.intro.title": "الدقة والخسارة",
            "insight.accuracy-and-loss.intro.lead": "فيما يلي إحصائيات حول دقة و خسارة النموذج الحالي خلال فترة التدريب الأخيرة <br> تحتوي الأسطر التي تحمل العلامة دقة التدريب و خسارة التدريب على البيانات أثناء العملية الفعلية مع البيانات التي شاهدها النموذج من قبل<br> توضح الخطوط التي تحمل تصنيف دقة التحقق من الصحة وفقدان التحقق من الصحة مدى أداء النموذج عند التنبؤ بالبيانات التي لم يشاهدها من قبل <br> في الحالة المثالية ، يتبع خط التحقق خط التدريب عن كثب",
            "insight.accuracy-and-loss.accuracy.title": "دقة",
            "insight.accuracy-and-loss.accuracy.subtitle": "كلما كان ذلك أفضل نسبة مئوية",
            "insight.accuracy-and-loss.accuracy.explanation": "يتم تحديد دقة النموذج بشكل عام بعد تسجيل معلمات النموذج وتعلمها وعدم وجود المزيد من التعلم يتم تقديم بيانات الاختبار إلى النموذج ويتم حفظ عدد الأخطاء (خسارة صفر واحد) التي يصنعها النموذج بعد إجراء المقارنة مع الملصقات الحقيقية ثم يتم حساب النسبة المئوية للمفاهيم الخاطئة <br> مثال: إذا كان عدد صور الاختبار هو 1000 وكان النموذج يصنف 952 من هذه الصور بشكل صحيح ، فعندئذ تكون دقة النموذج 95.2٪.",
            "insight.accuracy-and-loss.loss.title": "خسارة",
            "insight.accuracy-and-loss.loss.subtitle": "كلما كان ذلك أفضل",
            "insight.accuracy-and-loss.loss.explanation": "تتضمن قيمة الإصدار مدى جودة أو سوء أداء النموذج بعد كل تكرار للتحسين من الناحية المثالية ، يمكن توقع انخفاض هذه القيمة بعد كل تكرار يتم استخدام الخسارة للعثور على أفضل المعلمات للتدريب النموذجي (على سبيل المثال الأوزان في الشبكة العصبية) ويتم هذا التحسين عن طريق تحديث الأوزان",
            "insight.classification-report.intro.title": "تقرير التصنيف",
            "insight.classification-report.intro.lead": "عند اكتمال عملية التدريب ، يتم إنشاء تقرير تصنيف تلقائيًا ليتمكن من قياس أداء النموذج <br> تم إنشاء هذا التقرير من خلال عرض 10402 صورة لم يشاهدها النموذج من قبل يعطي النموذج تنبؤاته ، حيث يتم استخدام نتائجه ، إلى جانب التسمية الحقيقية المقابلة ، في وظائف رياضية مختلفة هذا يوفر الإحصاءات أدناه",
            "insight.classification-report.support.title": "دعم",
            "insight.classification-report.support.subtitle": "كم عدد الصور التي تحتوي عليها كل فئة من مجموعات بيانات الاختبار",
            "insight.classification-report.precision.title": "الدقة لكل فئة",
            "insight.classification-report.precision.subtitle": "نسبة مئوية",
            "insight.classification-report.precision.explanation": "الدقة - دقة التوقعات الإيجابية <br> يتم حساب الدقة باستخدام الصيغة التالية",
            "insight.classification-report.precision.formula": "الدقة = ايجابيات مبررة / (ايجابيات مبررة + ايجابيات كاذبة)",
            "insight.classification-report.recall.title": " تذكر النتيجة لكل فصل",
            "insight.classification-report.recall.subtitle": "نسبة مئوية",
            "insight.classification-report.recall.explanation": "تذكر (حساسية أو درجة الإيجابيات المبررة) - جزء من الإيجابيات التي تم تحديدها بشكل صحيح <br> يتم احتساب درجة الاستدعاء بالصيغة التالية",
            "insight.classification-report.recall.formula": "تذكر = إيجابيات مبررة / (إيجابيات مبررة + سلبيات خاطئة)",
            "insight.classification-report.f1.title": "F1 النتيجة لكل فئة",
            "insight.classification-report.f1.subtitle": "نسبة مئوية",
            "insight.classification-report.f1.explanation": "F1 Score - طريقة لمقارنة قيمتين F1-Score يأخذ في الاعتبار كل من الدقة والاستدعاء يتم تشكيلها من خلال إيجاد الانسجام في الدقة والتذكر <br> يتم احتساب درجة F1 وفقًا للمعادلة التالية",
            "insight.classification-report.f1.formula": "F1 = 2 × (الدقة والاستدعاء) / (الدقة + الاستدعاء)",
            "insight.confusion-matrix.intro.title": "مصفوفة الارتباك",
            "insight.confusion-matrix.intro.lead": "عند اكتمال عملية القطار ، يتم إنشاء مصفوفة الارتباك ، والتي توفر نظرة ثاقبة للتنبؤات التي أدلى بها النموذج من الناحية المثالية ، يجب أن يكون الخط القطري مرئيًا في المصفوفة",
            "insight.confusion-matrix.table.title": "مصفوفة الارتباك",
            "insight.confusion-matrix.table.subtitle": "مصفوفة واحدة ، لكل فصل",
            "insight.current-training.title": "التدريب الحالي",
            "insight.current-training.lead": "يجري باستمرار تكييف النموذج المستخدم في عمل التنبؤات مع البيانات الجديدة توفر الإحصاءات أدناه نظرة ثاقبة لعملية التدريب الحالية",
            "insight.current-training.progress.title": ":التقدم:",
            "insight.current-training.metrics.title": ":إحصائيات",
            "insight.current-training.metrics.accuracy": "دقة",
            "insight.current-training.metrics.validation-accuracy": "دقة التحقق من الصحة",
            "insight.current-training.metrics.loss": "خسارة",
            "insight.current-training.metrics.validation-loss": "فقدان التحقق من الصحة",
            "insight.current-situation.metrics.accuracy.popover": "يتم تحديد دقة النموذج بشكل عام بعد تسجيل معلمات النموذج وتعلمها وعدم وجود المزيد من التعلم يتم تقديم بيانات الاختبار إلى النموذج ويتم حفظ عدد الأخطاء (خسارة صفر واحد) التي يصنعها النموذج بعد إجراء المقارنة مع الملصقات الحقيقية ثم يتم حساب النسبة المئوية للمفاهيم الخاطئة <br> مثال: إذا كان عدد صور الاختبار هو 1000 وكان النموذج يصنف 952 من هذه الصور بشكل صحيح ، فعندئذ تكون دقة النموذج 95.2٪. <br> كلما كان ذلك أفضل",
            "insight.current-situation.metrics.validation-accuracy.popover": "يتم التعرف على دقة التحقق من الصحة بنفس طريقة الدقة <br> الفرق هو أن دقة التحقق يتم التعرف عليها على البيانات التي لم يسبق أن شاهدها النموذج <br> إذا كان النموذج مثاليًا ، فيجب أن تكون هذه القيمة هي نفسها الدقة هذا نادرا ما يحدث",
            "insight.current-situation.metrics.loss.popover": "تتضمن قيمة الإصدار مدى جودة أو سوء أداء النموذج بعد كل تكرار للتحسين من الناحية المثالية ، يمكن توقع انخفاض هذه القيمة بعد كل تكرار يتم استخدام الخسارة للعثور على أفضل المعلمات للتدريب النموذجي (على سبيل المثال الأوزان في الشبكة العصبية) ويتم هذا التحسين من خلال تحديث الأوزان <br> كلما كان ذلك أفضل ، كلما كان ذلك أفضل",
            "insight.current-situation.metrics.validation-loss.popover": "يتم احتساب خسارة التحقق من الصحة بالطريقة نفسها التي يتم بها حساب قيمة الخسارة ، والفرق هو أن هذه القيمة يتم حسابها على البيانات التي لم يشاهدها النموذج من قبل في الوضع المحافظ تساوي هذه القيمة قيمة الخسارة ، وهذا نادرًا ما يحدث",
            "insight.training-explanation.title": "ARGOS IRIS كيف يعمل",
            "insight.training-explanation.content": "عندما يتم إجراء تنبؤ باستخدام Argos IRIS ويتم الرد على الاستطلاع ، تتم إضافة بيانات جديدة إلى مجموعة البيانات الخاصة بنا هذه البيانات الجديدة في حد ذاتها لا تحسن النموذج يجب تحديث النموذج (الذي يتم به التنبؤات) بالبيانات الجديدة لهذا السبب ، بدأت عملية قطار جديدة <br> هذه العملية مستمرة وغير متزامنة مع خدمة التنبؤ الخاصة بنا بحيث لا يتم منع استخدام Argos IRIS <br> <br> النموذج الذي نستخدمه هو نموذج MobileNet مدرّب بعمق يتكون هذا النموذج من طبقات مختلفة ، تتحمل كل منها مسؤوليتها الخاصة <br> عند إجراء تنبؤ ، يتم عرض خريطة معالم ما يسمى بفهارس المراسلات مع الفئات المعروفة بناءً على أنماط معروفة تتم مقارنة خريطة الميزات هذه مع الفئات المعروفة لتكون قادرة على عمل تنبؤ <br> <br> أثناء عملية التدريب ، يتم إعطاء دفق من الصور إلى النموذج ، ومرة ​​أخرى يقوم النموذج بعمل تنبؤ لكل صورة في هذه الحالة ، يتم تضمين التسمية الصحيحة أيضًا في الصورة <br> حتى يتمكن النموذج من تحديث أوزانه بحيث يمكن استخدام الأنماط المأخوذة من الصورة للتعرف على الصور من نفس الفئة في المستقبل تستمر هذه العملية ويتعلم النموذج أنماطًا جديدة <br> تستمر هذه العملية لكل صورة في مجموعة البيانات ، ولمائة تكرار (أو عصر) عند الانتهاء من هذه العملية ، يتم تحميل النموذج الجديد ، ويتم إنشاء عدد قليل من الإحصائيات وإعادة تشغيل عملية القطار "
        },
        "fullname": "العربية",
        "force_rtl": true
    }
}